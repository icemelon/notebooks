{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "from hybrid_bert import get_hybrid_model, HybridBERTClassifier\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm import autotvm\n",
    "import tvm.contrib.graph_runtime as runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 256\n",
    "model_name = \"bert_12_768_12\"\n",
    "dataset = \"book_corpus_wiki_en_uncased\"\n",
    "\n",
    "mx_ctx = mx.cpu()\n",
    "bert, _ = get_hybrid_model(\n",
    "    name=model_name,\n",
    "    ctx=mx_ctx,\n",
    "    dataset_name=dataset,\n",
    "    pretrained=False,\n",
    "    use_pooler=True,\n",
    "    use_decoder=False,\n",
    "    use_classifier=False,\n",
    "    seq_length=seq_length)\n",
    "mx_model = HybridBERTClassifier(bert, num_classes=2, dropout=0.1)\n",
    "mx_model.initialize(ctx=mx_ctx)\n",
    "mx_model.hybridize(static_alloc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.00690419 -0.37328878]]\n",
      "<NDArray 1x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.randint(0, 1000, size=(1, seq_length)).astype('float32')\n",
    "token_types = np.random.choice((0, 1), size=(1, seq_length)).astype('float32')\n",
    "valid_length = np.asarray([seq_length]).astype('float32')\n",
    "\n",
    "inputs_nd = mx.nd.array(inputs, ctx=mx_ctx)\n",
    "token_types_nd = mx.nd.array(token_types, ctx=mx_ctx)\n",
    "valid_length_nd = mx.nd.array(valid_length, ctx=mx_ctx)\n",
    "mx_out = mx_model(inputs_nd, token_types_nd, valid_length_nd)\n",
    "print(mx_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mxnet latency: 301.09 ms\n"
     ]
    }
   ],
   "source": [
    "# dry run\n",
    "for _ in range(10):\n",
    "    mx_model(inputs_nd, token_types_nd, valid_length_nd).wait_to_read()\n",
    "\n",
    "min_repeat_ms = 2000\n",
    "number = 20\n",
    "while True:\n",
    "    beg = time.time()\n",
    "    for _ in range(number):\n",
    "        mx_model(inputs_nd, token_types_nd, valid_length_nd).wait_to_read()\n",
    "    end = time.time()\n",
    "    lat = (end - beg) * 1e3\n",
    "    if lat >= min_repeat_ms:\n",
    "        break\n",
    "    number = int(max(min_repeat_ms / (lat / number) + 1, number * 1.618))\n",
    "print('mxnet latency: %.2f ms' % (lat / number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_dict = {\n",
    "    'data0': (1, seq_length),\n",
    "    'data1': (1, seq_length),\n",
    "    'data2': (1,)\n",
    "}\n",
    "mod, params = relay.frontend.from_mxnet(mx_model, shape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=llvm -mcpu=skylake-avx512 -libs=cblas, workload=('dense', (1, 768, 'float32'), (2, 768, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -mcpu=skylake-avx512 -libs=cblas, workload=('dense', (1, 768, 'float32'), (768, 768, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -mcpu=skylake-avx512 -libs=cblas, workload=('dense', (256, 3072, 'float32'), (768, 3072, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -mcpu=skylake-avx512 -libs=cblas, workload=('dense', (256, 768, 'float32'), (3072, 768, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -mcpu=skylake-avx512 -libs=cblas, workload=('dense', (256, 768, 'float32'), (768, 768, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -mcpu=skylake-avx512 -libs=cblas, workload=('batch_matmul', (12, 256, 256, 'float32'), (12, 64, 256, 'float32')). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -mcpu=skylake-avx512 -libs=cblas, workload=('batch_matmul', (12, 256, 64, 'float32'), (12, 256, 64, 'float32')). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    }
   ],
   "source": [
    "ctx = tvm.cpu()\n",
    "target = \"llvm -mcpu=skylake-avx512 -libs=cblas\"\n",
    "\n",
    "with relay.build_config(opt_level=3):\n",
    "    graph, lib, new_params = relay.build(mod[\"main\"], target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00690407 -0.37329033]]\n"
     ]
    }
   ],
   "source": [
    "ex = runtime.create(graph, lib, ctx)\n",
    "ex.set_input(data0=inputs, data1=token_types, data2=valid_length, **new_params)\n",
    "ex.run()\n",
    "out = ex.get_output(0)\n",
    "print(out)\n",
    "\n",
    "# check correctness\n",
    "tvm.testing.assert_allclose(out.asnumpy(), mx_out.asnumpy(), rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TVM latency for seq length 256: 55.47 ms\n"
     ]
    }
   ],
   "source": [
    "# benchmark\n",
    "ftimer = ex.module.time_evaluator(\"run\", ctx, min_repeat_ms=2000)\n",
    "prof_res = np.array(ftimer().results) * 1000  # convert to millisecond\n",
    "print(\"TVM latency for seq length %s: %.2f ms\" % (seq_length, np.mean(prof_res)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
